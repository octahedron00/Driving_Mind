{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install nvidia_smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from ultralytics import YOLO, RTDETR\n",
    "import nvidia_smi\n",
    "\n",
    "nvidia_smi.nvmlInit()\n",
    "handle = nvidia_smi.nvmlDeviceGetHandleByIndex(0)\n",
    "\n",
    "\n",
    "\n",
    "# 마음껏 수정하며 진행할 것.\n",
    "\n",
    "DO_SECOND = False\n",
    "FILE_1 = \"rtdetr-l.pt\"\n",
    "FILE_2 = \"yolo11l.pt\"\n",
    "# FILE_1_TRT = \"rtdetr-l.onnx\"\n",
    "# FILE_2_TRT = \"yolo11l.engine\"\n",
    "\n",
    "IMG_SIZE = (640, 640, 3)\n",
    "IMG_TEST = np.zeros(IMG_SIZE)\n",
    "\n",
    "print(\"All import finished\")\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "model_1 = RTDETR(FILE_1)\n",
    "# model_1.to('cuda')\n",
    "print(f\"Model 1 Starting: {time.time()-start_time:.03f} seconds\")\n",
    "\n",
    "# model_1.export(format=\"onnx\")\n",
    "\n",
    "# model_1 = RTDETR(FILE_1_TRT)\n",
    "\n",
    "if DO_SECOND:\n",
    "    start_time = time.time()\n",
    "    model_2 = YOLO(FILE_2)\n",
    "    # model_2.to('cuda')\n",
    "    print(f\"Model 2 Starting: {time.time()-start_time:.03f} seconds\")\n",
    "\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "model_1.predict(IMG_TEST)\n",
    "print(f\"Model 1 First inference: {time.time()-start_time:.03f} seconds\")\n",
    "\n",
    "if DO_SECOND:\n",
    "    start_time = time.time()\n",
    "    model_2.predict(IMG_TEST)\n",
    "    print(f\"Model 2 First inference: {time.time()-start_time:.03f} seconds\")\n",
    "\n",
    "\n",
    "\n",
    "# card id 0 hardcoded here, there is also a call to get all available card ids, so we could iterate\n",
    "\n",
    "info = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)\n",
    "\n",
    "print(f\"Total memory:{ (info.total/1073741824):03f} GB\")\n",
    "print(f\"Free memory:{ (info.free/1073741824):03f} GB\")\n",
    "print(f\"Used memory:{ (info.used/1073741824):03f} GB\")\n",
    "\n",
    "nvidia_smi.nvmlShutdown()\n",
    "\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    start_time = time.time()\n",
    "    model_1.predict(IMG_TEST)\n",
    "    print(f\"Model 1 RealTime inference: {time.time()-start_time:.03f} seconds\")\n",
    "\n",
    "    if DO_SECOND:\n",
    "        start_time = time.time()\n",
    "        model_2.predict(IMG_TEST)\n",
    "        print(f\"Model 2 RealTime inference: {time.time()-start_time:.03f} seconds\")\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
